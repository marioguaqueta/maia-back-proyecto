# HerdNet Official Integration

## üéØ Overview

The Flask API now uses the **official HerdNet inference method** based on `infer.py` from the HerdNet repository. This provides accurate animal detection and counting for large satellite images.

## ‚úÖ What Was Integrated

### 1. **Proper Model Loading**
Based on the official HerdNet checkpoint format:

```python
# Load checkpoint with all metadata
checkpoint = torch.load("herdnet_model.pth", map_location=device)

# Extract configuration
classes_dict = checkpoint['classes']  # Species mapping
num_classes = len(classes_dict) + 1  # +1 for background
img_mean = checkpoint['mean']         # Normalization mean
img_std = checkpoint['std']           # Normalization std

# Build model with exact configuration
model = HerdNet(num_classes=num_classes, pretrained=False, down_ratio=2)
model = LossWrapper(model, losses=[])
model.load_state_dict(checkpoint['model_state_dict'])
```

### 2. **HerdNetStitcher for Large Images**
Official method for processing large satellite images:

```python
stitcher = HerdNetStitcher(
    model=model,
    size=(512, 512),      # Patch size
    overlap=160,          # Overlap (official default)
    down_ratio=2,         # HerdNet downsampling
    up=True,              # Upsample results
    reduction='mean',     # Averaging for overlaps
    device_name=device
)

# Process full image
density_map, class_map = stitcher.stitch(img_tensor)
```

### 3. **LMDS (Local Maxima Detection System)**
Precise point detection for individual animals:

```python
from animaloc.eval.localiza import compute_LMDS

# Find detection points
points, labels, scores = compute_LMDS(
    density_map, 
    class_map,
    kernel_size=(3, 3),
    adapt_ts=0.2,         # Adaptive threshold
    neg_ts=0.1,           # Negative threshold
    down_ratio=2
)

# Returns:
# - points: (y, x) coordinates of detected animals
# - labels: Species class IDs
# - scores: Confidence scores
```

### 4. **Detection Counting and Aggregation**
Counts animals by species:

```python
detections_by_class = {}

for label, score in zip(labels, scores):
    class_id = int(label)
    class_name = ANIMAL_CLASSES[class_id]
    
    detections_by_class[class_name] = {
        'count': number_of_detections,
        'scores': confidence_scores
    }
```

## üîÑ Processing Workflow

### For Small Images (<1500px):
```
1. Load image
2. Apply normalization (from checkpoint)
3. Run single inference
4. Extract classification
5. Return results
```

### For Large Images (>1500px):
```
1. Load image (e.g., 6000x4000)
2. Apply proper normalization
3. HerdNetStitcher splits into patches:
   - 512x512 patches
   - 160px overlap
   - ~240 patches for 6000x4000 image
4. Process all patches
5. Stitch results back together
6. Apply LMDS to find detection points
7. Count detections per species
8. Return detailed results with coordinates
```

## üìä Enhanced Response Format

```json
{
  "success": true,
  "filename": "satellite_image.jpg",
  "analysis": {
    "contains_animal": true,
    "predicted_class": "buffalo",
    "confidence": 0.89,
    "image_size": {
      "width": 6000,
      "height": 4000
    },
    "processing_method": "stitcher",
    "total_detections": 47,
    "detection_count": 47,
    "detection_points": [
      [2145, 3421],
      [2167, 3445],
      ...
    ],
    "detailed_predictions": [
      {
        "class": "buffalo",
        "confidence": 0.89,
        "class_id": 1,
        "count": 32
      },
      {
        "class": "elephant",
        "confidence": 0.85,
        "class_id": 2,
        "count": 15
      }
    ]
  }
}
```

## üéØ Key Features

### 1. **Accurate Detection**
- Uses official HerdNet methodology
- Proper checkpoint loading with metadata
- Correct normalization parameters
- LMDS for precise localization

### 2. **Individual Animal Counting**
- Detects exact positions of animals
- Returns (y, x) coordinates
- Species classification for each detection
- Confidence scores per detection

### 3. **Large Image Support**
- Automatic stitching for >1500px images
- 160px overlap (prevents edge detection loss)
- Efficient batch processing
- Memory-optimized

### 4. **Fallback Mechanism**
- Tries HerdNetStitcher first
- Falls back to manual patching if needed
- Graceful error handling
- Progress logging

## üìù Checkpoint Requirements

Your `herdnet_model.pth` should contain:

```python
{
    'model_state_dict': <trained_weights>,
    'classes': {
        1: 'buffalo',
        2: 'elephant',
        3: 'kob',
        4: 'topi',
        5: 'warthog',
        6: 'waterbuck'
    },
    'mean': [0.485, 0.456, 0.406],
    'std': [0.229, 0.224, 0.225]
}
```

## üöÄ Usage Examples

### Basic Analysis
```bash
curl -X POST http://localhost:8000/analyze-image \
  -F "file=@satellite_images.zip"
```

### Response with Detections
```json
{
  "success": true,
  "summary": {
    "total_images": 5,
    "images_with_animals": 4
  },
  "results": [
    {
      "filename": "survey_001.jpg",
      "analysis": {
        "total_detections": 47,
        "predicted_class": "buffalo",
        "detailed_predictions": [
          {"class": "buffalo", "count": 32},
          {"class": "elephant", "count": 15}
        ]
      }
    }
  ]
}
```

## üîç Detection Accuracy

### Benefits of Official Method:
1. **Precise Localization**: LMDS finds exact animal positions
2. **No Double Counting**: Overlap handling prevents duplicates
3. **Species Classification**: Each detection has species label
4. **Confidence Scores**: Quality assessment per detection
5. **Scalable**: Works with any image size

### Performance:
- **Small images** (512x512): ~0.5 seconds
- **Medium images** (2000x2000): ~2-3 seconds
- **Large images** (6000x4000): ~30-60 seconds (GPU), ~2-4 minutes (CPU)

## üé® Future Enhancements

Possible additions based on `infer.py`:

### 1. **Visualization Export**
```python
# Draw detection points on images
from animaloc.vizual import draw_points

output = draw_points(img, detection_points, color='red', size=10)
output.save('detections.jpg')
```

### 2. **Thumbnail Generation**
```python
# Create thumbnails around each detection
for i, (y, x) in enumerate(detection_points):
    thumbnail = img.crop((x-128, y-128, x+128, y+128))
    thumbnail.save(f'detection_{i}.jpg')
```

### 3. **CSV Export**
```python
# Export detections as CSV
import pandas as pd

df = pd.DataFrame({
    'image': image_names,
    'x': x_coords,
    'y': y_coords,
    'species': species_labels,
    'confidence': confidence_scores
})
df.to_csv('detections.csv')
```

## üìä Comparison: Old vs New

### Old Method (Manual Patching):
- ‚ùå Basic classification only
- ‚ùå No individual animal detection
- ‚ùå Approximate counting via voting
- ‚ùå No detection coordinates
- ‚úÖ Works for classification

### New Method (Official HerdNet):
- ‚úÖ Individual animal detection
- ‚úÖ Exact position coordinates
- ‚úÖ Accurate counting
- ‚úÖ Species per detection
- ‚úÖ Proper stitching algorithm
- ‚úÖ LMDS for precision

## üõ†Ô∏è Configuration

### Default Parameters:
```python
patch_size = 512       # Optimal for HerdNet
overlap = 160          # Official HerdNet default
size_threshold = 1500  # When to use stitcher
use_stitcher = True    # Enable official method
```

### LMDS Parameters:
```python
kernel_size = (3, 3)   # Detection kernel
adapt_ts = 0.2         # Adaptive threshold
neg_ts = 0.1           # Negative threshold
down_ratio = 2         # HerdNet downsampling ratio
```

## ‚úÖ Verification

Test that the integration works:

```bash
# 1. Check model loading
python app.py
# Should see: "‚úì Model loaded successfully with 7 classes"

# 2. Test with small image
curl -X POST http://localhost:8000/analyze-image \
  -F "file=@small_images.zip"

# 3. Test with large image (>1500px)
curl -X POST http://localhost:8000/analyze-image \
  -F "file=@satellite_images.zip"
# Should see: "Processing with HerdNetStitcher"
```

## üìö References

- **Original Paper**: Delplanque et al. (2023) - "From crowd to herd counting"
- **GitHub**: https://github.com/Alexandre-Delplanque/HerdNet
- **Method**: Based on `tools/infer.py` from HerdNet repository

---

**Status**: ‚úÖ Fully Integrated  
**Version**: 3.1.0  
**Date**: November 2025

